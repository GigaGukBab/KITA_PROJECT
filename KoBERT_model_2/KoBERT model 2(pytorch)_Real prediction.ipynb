{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-iFfqfH7Xik"
   },
   "source": [
    "# **KoBERT Model with fine tuning**\n",
    "\n",
    " - 2번분석, 발화 내용 기반 보이스피싱 발화문, 일반 상담 발화문 감정 판별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gNaiWhP17Xio"
   },
   "outputs": [],
   "source": [
    "# # 원본 https://github.com/SKTBrain/KoBERT에 나와있는 using pytorch 코드\n",
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IX4wdoTN7Xip",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/mldl_torch/lib/python3.8/site-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n"
     ]
    }
   ],
   "source": [
    "# # RUN\n",
    "# 필요 import 문 \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np  # 'ersion : '1.23.5'\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 원본 https://github.com/SKTBrain/KoBERT에 나와있는 using pytorch 코드\n",
    "# from kobert import get_tokenizer\n",
    "# from kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 원본 https://github.com/SKTBrain/KoBERT에 나와있는 using pytorch 코드\n",
    "# bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace 우회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RUN\n",
    "# ModuleNotFoundError: No module named 'kobert'로 인한 허깅페이스 우회\n",
    "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RUN\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RUN\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
    "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Qn13zOr57Xiq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 12:48:28.230979: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-13 12:48:28.270647: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-13 12:48:28.272161: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-13 12:48:29.221483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# RUN\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "p9YRdvhE7Xiq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.10.1+cu102\n",
      "현재 가상환경 GPU 사용 가능상태\n"
     ]
    }
   ],
   "source": [
    "# # RUN\n",
    "# # 그래픽 카드 사용\n",
    "print('torch version: {}'.format(torch.__version__))\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('현재 가상환경 GPU 사용 가능상태')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU 사용 불가능 상태')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용하는 Graffic card 이름 확인\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.00 MB\n",
      "Reserved memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "# GPU 용량 확인\n",
    "# Get the current memory usage (in bytes)\n",
    "allocated = torch.cuda.memory_allocated(device)\n",
    "reserved = torch.cuda.memory_reserved(device)\n",
    "\n",
    "# Convert to MB\n",
    "allocated_mb = allocated / 1024 / 1024\n",
    "reserved_mb = reserved / 1024 / 1024\n",
    "\n",
    "print(f'Allocated memory: {allocated_mb:.2f} MB')\n",
    "print(f'Reserved memory: {reserved_mb:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### KoBERT 모델 관련 코드 #####\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert, hidden_size=768, num_classes=4, dr_rate=None, params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "\n",
    "        _, pooler = self.bert(input_ids=token_ids, token_type_ids=segment_ids.long(), attention_mask=attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 정의\n",
    "\n",
    "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model\n",
    "model_path = '/KITA_Project/Final Model for KoBERT/final_model_koBERT_vp_sem_clf.pt'  # adjust the path if needed\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, vocab, pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, vocab=vocab, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 : 안녕하세요\n",
      ">> 입력하신 문장은 99.51%의 확률로 \"중립\"감정이 느껴지는 문장입니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 네, 쿠폰은 같이 드립니다. 단 삼 단계는 현재 재고가 다 소진되어 있습니다.\n",
      ">> 입력하신 문장은 96.14%의 확률로 \"화남\"감정이 느껴지는 문장입니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 이용권에 따라 다릅니다.\n",
      ">> 입력하신 문장은 90.92%의 확률로 \"화남\"감정이 느껴지는 문장입니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 그러면 지금 스마트 뱅킹이나 인터넷 뱅킹을 사용하고 계신 건가요?\n",
      ">> 입력하신 문장은 92.77%의 확률로 \"화남\"감정이 느껴지는 문장입니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 저희 농협 대출 나가면 그거 가지고 친구분한테 빌렸던 거 갚아주면 되는 거니까요.\n",
      ">> 입력하신 문장은 98.68%의 확률로 \"화남\"감정이 느껴지는 문장입니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 0\n"
     ]
    }
   ],
   "source": [
    "def predict(predict_sentence):\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "    \n",
    "    # Define the maximum length for the tokens. You can adjust this value.\n",
    "    max_len = 64\n",
    "    \n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tokenizer, max_len, vocab, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=1, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    sentiment_labels = [\"중립\", \"화남\", \"역겨움\", \"두려움\"]\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length = valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        probs = F.softmax(out, dim=1)  # Convert logits to probabilities\n",
    "\n",
    "        # Get the predicted label and its probability\n",
    "        predicted_label_idx = torch.argmax(out).item()\n",
    "        predicted_label_prob = probs[0][predicted_label_idx].item() * 100  # Convert to percentage\n",
    "\n",
    "        print(f\">> 입력하신 문장은 {predicted_label_prob:.2f}%의 확률로 \\\"{sentiment_labels[predicted_label_idx]}\\\"감정이 느껴지는 문장입니다.\")\n",
    "\n",
    "# User input loop\n",
    "end = 1\n",
    "while end == 1:\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
    "    if sentence == \"0\":\n",
    "        break\n",
    "    predict(sentence)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mldl_torch",
   "language": "python",
   "name": "mldl_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
